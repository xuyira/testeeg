"""
æŸ¥çœ‹ EEG æ‰©æ•£æ¨¡å‹çš„æ¶æ„å’Œå‚æ•°é‡
"""

import torch
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from eeg_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
)

def count_parameters(model):
    """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params, trainable_params

def format_number(num):
    """æ ¼å¼åŒ–æ•°å­—ï¼ˆæ·»åŠ åƒä½åˆ†éš”ç¬¦å’Œå•ä½ï¼‰"""
    if num >= 1e9:
        return f"{num/1e9:.2f}B"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)

def main():
    print("="*80)
    print("EEG æ‰©æ•£æ¨¡å‹ä¿¡æ¯")
    print("="*80)
    print()
    
    # æ ¹æ®æ‚¨çš„è®­ç»ƒå‚æ•°åˆ›å»ºæ¨¡å‹
    config = {
        'image_size': 64,
        'in_channels': 22,           # EEG é€šé“æ•°
        'num_channels': 128,         # åŸºç¡€é€šé“æ•°
        'num_res_blocks': 2,         # æ¯å±‚çš„æ®‹å·®å—æ•°é‡
        'learn_sigma': True,
        'class_cond': False,
        'use_fp16': True,
        'attention_resolutions': "32,16,8",
        'dropout': 0.1,
        'noise_schedule': 'cosine',
        'num_head_channels': 64,
        'resblock_updown': True,
        'use_new_attention_order': True,
        'use_scale_shift_norm': True,
        'diffusion_steps': 1000,
        'timestep_respacing': "",
    }
    
    print("ğŸ“‹ æ¨¡å‹é…ç½®:")
    print("-"*80)
    print(f"  æ¨¡å‹ç±»å‹:          UNet (æ—¶é—´æ­¥æ¡ä»¶æ‰©æ•£æ¨¡å‹)")
    print(f"  è¾“å…¥å¤§å°:          {config['image_size']}x{config['image_size']}")
    print(f"  è¾“å…¥é€šé“:          {config['in_channels']} (EEGé€šé“æ•°)")
    print(f"  åŸºç¡€é€šé“æ•°:        {config['num_channels']}")
    print(f"  æ®‹å·®å—æ•°é‡/å±‚:     {config['num_res_blocks']}")
    print(f"  æ³¨æ„åŠ›åˆ†è¾¨ç‡:      {config['attention_resolutions']}")
    print(f"  æ³¨æ„åŠ›å¤´é€šé“æ•°:    {config['num_head_channels']}")
    print(f"  Dropout:           {config['dropout']}")
    print(f"  å­¦ä¹  Sigma:        {config['learn_sigma']}")
    print(f"  ä½¿ç”¨ FP16:         {config['use_fp16']}")
    print(f"  æ®‹å·®ä¸Šä¸‹é‡‡æ ·:      {config['resblock_updown']}")
    print(f"  Scale-Shift Norm:  {config['use_scale_shift_norm']}")
    print(f"  å™ªå£°è°ƒåº¦:          {config['noise_schedule']}")
    print(f"  æ‰©æ•£æ­¥æ•°:          {config['diffusion_steps']}")
    print()
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ”¨ åˆ›å»ºæ¨¡å‹...")
    model, diffusion = create_model_and_diffusion(**config)
    
    # è®¡ç®—å‚æ•°é‡
    total_params, trainable_params = count_parameters(model)
    
    print()
    print("="*80)
    print("ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡")
    print("="*80)
    print(f"  æ€»å‚æ•°é‡:          {total_params:,} ({format_number(total_params)})")
    print(f"  å¯è®­ç»ƒå‚æ•°:        {trainable_params:,} ({format_number(trainable_params)})")
    print(f"  å†…å­˜å ç”¨ï¼ˆFP32ï¼‰:  çº¦ {total_params * 4 / 1024 / 1024:.2f} MB")
    print(f"  å†…å­˜å ç”¨ï¼ˆFP16ï¼‰:  çº¦ {total_params * 2 / 1024 / 1024:.2f} MB")
    print()
    
    # æ¨¡å‹æ¶æ„è¯¦æƒ…
    print("="*80)
    print("ğŸ—ï¸  æ¨¡å‹æ¶æ„")
    print("="*80)
    print()
    
    # è·å–é€šé“å€æ•°
    from eeg_adapt.guided_diffusion.script_util import model_and_diffusion_defaults
    defaults = model_and_diffusion_defaults()
    channel_mult = defaults.get('channel_mult', '')
    if channel_mult == '':
        # æ ¹æ® image_size è‡ªåŠ¨è®¡ç®—
        if config['image_size'] == 64:
            channel_mult = (1, 2, 3, 4)
        elif config['image_size'] == 128:
            channel_mult = (1, 2, 2, 2, 2)
        elif config['image_size'] == 256:
            channel_mult = (1, 1, 2, 2, 4, 4)
        else:
            channel_mult = (1, 2, 4, 8)
    
    print("UNet ç»“æ„:")
    print(f"  åŸºç¡€é€šé“: {config['num_channels']}")
    print(f"  é€šé“å€æ•°: {channel_mult}")
    print()
    
    # è®¡ç®—æ¯å±‚çš„é€šé“æ•°
    print("å„å±‚é€šé“æ•°:")
    for i, mult in enumerate(channel_mult):
        channels = config['num_channels'] * mult
        resolution = config['image_size'] // (2 ** i)
        has_attention = str(resolution) in config['attention_resolutions'].split(',')
        attention_mark = " [+Attention]" if has_attention else ""
        print(f"  å±‚ {i}: {resolution:3d}x{resolution:3d} â†’ {channels:4d} é€šé“ Ã— {config['num_res_blocks']} æ®‹å·®å—{attention_mark}")
    
    print()
    print("æ—¶é—´æ­¥åµŒå…¥ç»´åº¦:", config['num_channels'] * 4)
    
    # è¾“å‡ºé€šé“
    out_channels = config['in_channels'] * 2 if config['learn_sigma'] else config['in_channels']
    print(f"è¾“å‡ºé€šé“æ•°: {out_channels} ({'å­¦ä¹ æ–¹å·®' if config['learn_sigma'] else 'å›ºå®šæ–¹å·®'})")
    
    print()
    print("="*80)
    print("ğŸ¯ æ¨¡å‹ç±»å‹æ€»ç»“")
    print("="*80)
    print()
    print(f"  æ¨¡å‹åç§°:    æ—¶é—´æ­¥æ¡ä»¶ UNet æ‰©æ•£æ¨¡å‹")
    print(f"  è®ºæ–‡æ¥æº:    åŸºäº DDPM/Improved DDPM æ¶æ„")
    print(f"  æ”¹è¿›:        æ”¯æŒ EEG å¤šé€šé“è¾“å…¥ï¼ˆ22é€šé“ï¼‰")
    print(f"  æ€»å‚æ•°é‡:    {format_number(total_params)}")
    print(f"  è§„æ¨¡ç­‰çº§:    {'å°å‹æ¨¡å‹ (< 100M)' if total_params < 100e6 else 'ä¸­å‹æ¨¡å‹ (100M-500M)' if total_params < 500e6 else 'å¤§å‹æ¨¡å‹ (> 500M)'}")
    print()
    
    # å¯¹æ¯”å…¶ä»–æ¨¡å‹
    print("="*80)
    print("ğŸ“ˆ å‚æ•°é‡å¯¹æ¯”")
    print("="*80)
    print()
    print(f"  æ‚¨çš„ EEG æ‰©æ•£æ¨¡å‹:     {format_number(total_params)}")
    print(f"  DDPM (ImageNet):       çº¦ 60M")
    print(f"  Stable Diffusion:      çº¦ 860M")
    print(f"  DALL-E 2:              çº¦ 3.5B")
    print()
    print(f"  æ‚¨çš„æ¨¡å‹è§„æ¨¡ç›¸å½“äº DDPM çš„ {total_params/60e6:.2f}x")
    print()
    
    print("="*80)
    print("âœ… åˆ†æå®Œæˆ")
    print("="*80)

if __name__ == "__main__":
    main()

