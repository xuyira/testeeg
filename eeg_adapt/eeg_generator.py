"""
EEG ä¿¡å·ç”Ÿæˆå™¨ - å‡½æ•°å¼æ¥å£
å¯ä»¥åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ç›´æ¥è°ƒç”¨ï¼Œè¿”å›åŸå§‹ä¿¡å·å’Œç”Ÿæˆä¿¡å·
"""

import numpy as np
import torch as th
from typing import Tuple, Optional, Dict
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
if script_dir not in sys.path:
    sys.path.insert(0, script_dir)

from eeg_adapt.guided_diffusion import dist_util
from eeg_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
)


class EEGGenerator:
    """
    EEG ä¿¡å·ç”Ÿæˆå™¨ç±»
    
    ä½¿ç”¨ç¤ºä¾‹:
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = EEGGenerator(model_path="models/model.pt")
        
        # ç”Ÿæˆä¿¡å·
        original, generated = generator.generate(eeg_data)
        
        # æ‰¹é‡ç”Ÿæˆ
        for original_batch, generated_batch in generator.generate_batches(eeg_data, batch_size=16):
            # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
            pass
    """
    
    def __init__(
        self,
        model_path: str,
        device: Optional[str] = None,
        D: int = 8,
        scale: float = 1.0,
        N: Optional[int] = None,
        embedding_size: int = 64,
        delay: int = 15,
        image_size: int = 64,
        in_channels: int = 22,
        diffusion_steps: int = 1000,
        noise_schedule: str = "linear",
        **model_kwargs
    ):
        """
        åˆå§‹åŒ– EEG ç”Ÿæˆå™¨
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            device: æŒ‡å®šè®¾å¤‡ ("cuda", "cpu", None=è‡ªåŠ¨æ£€æµ‹)
            D: é¢‘ç‡å¼•å¯¼ä¸‹é‡‡æ ·å€æ•°
            scale: é¢‘ç‡å¼•å¯¼å¼ºåº¦
            N: èµ·å§‹æ—¶é—´æ­¥ï¼ˆNone=ä»å¤´å¼€å§‹ï¼‰
            embedding_size: æ—¶é—´å»¶è¿ŸåµŒå…¥ç»´åº¦
            delay: å»¶è¿ŸåµŒå…¥çš„delayå‚æ•°
            image_size: å›¾åƒå¤§å°
            in_channels: è¾“å…¥é€šé“æ•°ï¼ˆEEGä¸º22ï¼‰
            diffusion_steps: æ‰©æ•£æ­¥æ•°
            noise_schedule: å™ªå£°è°ƒåº¦
            **model_kwargs: å…¶ä»–æ¨¡å‹å‚æ•°
        """
        self.model_path = model_path
        self.D = D
        self.scale = scale
        self.N = N
        self.embedding_size = embedding_size
        self.delay = delay
        
        # è®¾ç½®è®¾å¤‡
        if device is None:
            self.device = dist_util.dev()
        else:
            self.device = th.device(device)
        
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # æ¨¡å‹é…ç½®ï¼ˆä½¿ç”¨å®Œæ•´çš„é»˜è®¤å‚æ•°ï¼‰
        from eeg_adapt.guided_diffusion.script_util import model_and_diffusion_defaults
        
        # è·å–æ‰€æœ‰é»˜è®¤å‚æ•°
        model_config = model_and_diffusion_defaults()
        
        # æ›´æ–°å…³é”®å‚æ•°
        model_config.update({
            'image_size': image_size,
            'in_channels': in_channels,
            'num_channels': 128,
            'num_res_blocks': 2,
            'num_heads': 4,
            'num_head_channels': 64,
            'attention_resolutions': "32,16,8",
            'dropout': 0.1,
            'diffusion_steps': diffusion_steps,
            'noise_schedule': noise_schedule,
            'learn_sigma': True,
            'class_cond': False,
            'use_checkpoint': False,
            'use_scale_shift_norm': True,
            'resblock_updown': True,
            'use_fp16': True,
            'use_new_attention_order': True,
            'timestep_respacing': "",
        })
        
        # åº”ç”¨ç”¨æˆ·æä¾›çš„å…¶ä»–å‚æ•°
        model_config.update(model_kwargs)
        
        # åˆ›å»ºæ¨¡å‹
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
        self.model, self.diffusion = create_model_and_diffusion(**model_config)
        self.model.load_state_dict(
            dist_util.load_state_dict(model_path, map_location="cpu")
        )
        self.model.to(self.device)
        
        # å¦‚æœä½¿ç”¨ FP16ï¼Œéœ€è¦è½¬æ¢æ¨¡å‹
        if model_config.get('use_fp16', False):
            self.model.convert_to_fp16()
            print(f"ğŸ”§ å·²è½¬æ¢ä¸º FP16 æ¨¡å¼")
        
        self.model.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
        # åˆå§‹åŒ– embedder
        from eeg_adapt.scripts.eeg_sample import DelayEmbedder, img_to_ts
        self.DelayEmbedder = DelayEmbedder
        self.img_to_ts = img_to_ts
    
    def _normalize_data(self, data: np.ndarray) -> Tuple[np.ndarray, float, float]:
        """å½’ä¸€åŒ–æ•°æ®åˆ° [-1, 1]"""
        data_min = data.min()
        data_max = data.max()
        
        if -1.1 <= data_min and data_max <= 1.1:
            return data, data_min, data_max
        else:
            normalized = 2 * (data - data_min) / (data_max - data_min) - 1
            return normalized, data_min, data_max
    
    def _denormalize_data(self, data: np.ndarray, data_min: float, data_max: float) -> np.ndarray:
        """åå½’ä¸€åŒ–æ•°æ®"""
        return (data + 1) / 2 * (data_max - data_min) + data_min
    
    def _eeg_to_image(self, eeg_data: np.ndarray) -> th.Tensor:
        """
        å°† EEG æ—¶é—´åºåˆ—è½¬æ¢ä¸ºå›¾åƒæ ¼å¼
        
        Args:
            eeg_data: (trials, channels, timepoints) æˆ– (trials, timepoints, channels)
        
        Returns:
            images: (trials, channels, height, width)
        """
        # ç¡®ä¿æ•°æ®æ ¼å¼ä¸º (trials, channels, timepoints)
        if eeg_data.ndim == 4 and eeg_data.shape[1] == 1:
            eeg_data = eeg_data.squeeze(1)
        
        if eeg_data.shape[1] == 1000 and eeg_data.shape[2] == 22:
            eeg_data = np.transpose(eeg_data, (0, 2, 1))
        
        # è½¬æ¢ä¸º (trials, timepoints, channels)
        eeg_data_transposed = np.transpose(eeg_data, (0, 2, 1))
        
        # åˆ›å»º embedder
        seq_len = eeg_data.shape[2]
        embedder = self.DelayEmbedder(self.device, seq_len, self.delay, self.embedding_size)
        
        # è½¬æ¢ä¸ºå›¾åƒ
        batch_tensor = th.from_numpy(eeg_data_transposed).float().to(self.device)
        images = embedder.ts_to_img(batch_tensor, pad=True, mask=0)
        
        return images
    
    def _image_to_eeg(self, images: th.Tensor) -> np.ndarray:
        """
        å°†å›¾åƒæ ¼å¼è½¬æ¢å› EEG æ—¶é—´åºåˆ—
        
        Args:
            images: (trials, channels, height, width)
        
        Returns:
            eeg_data: (trials, channels, timepoints)
        """
        signals = self.img_to_ts(images)  # (trials, timepoints, channels)
        signals = signals.permute(0, 2, 1)  # (trials, channels, timepoints)
        return signals.cpu().detach().numpy()
    
    def generate(
        self,
        eeg_data: np.ndarray,
        return_images: bool = False,
        verbose: bool = True
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        ç”Ÿæˆ EEG ä¿¡å·
        
        Args:
            eeg_data: è¾“å…¥ EEG æ•°æ®
                     æ ¼å¼: (trials, channels, timepoints) æˆ– (trials, 22, 1000)
            return_images: æ˜¯å¦åŒæ—¶è¿”å›å›¾åƒæ ¼å¼
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
        Returns:
            original_signals: åŸå§‹ä¿¡å· (trials, channels, timepoints)
            generated_signals: ç”Ÿæˆä¿¡å· (trials, channels, timepoints)
            å¦‚æœ return_images=Trueï¼Œè¿˜ä¼šè¿”å›:
                (original_signals, generated_signals, original_images, generated_images)
        """
        if verbose:
            print(f"\nğŸ”„ ç”Ÿæˆ EEG ä¿¡å·...")
            print(f"   è¾“å…¥å½¢çŠ¶: {eeg_data.shape}")
        
        # ä¿å­˜åŸå§‹æ•°æ®ï¼ˆç”¨äºè¿”å›ï¼‰
        original_data = eeg_data.copy()
        
        # å½’ä¸€åŒ–
        eeg_data_normalized, data_min, data_max = self._normalize_data(eeg_data)
        
        if verbose:
            print(f"   æ•°æ®èŒƒå›´: [{data_min:.4f}, {data_max:.4f}]")
        
        # è½¬æ¢ä¸ºå›¾åƒ
        images = self._eeg_to_image(eeg_data_normalized)
        
        if verbose:
            print(f"   å›¾åƒå½¢çŠ¶: {images.shape}")
        
        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        model_kwargs = {"ref_img": images}
        
        # ç”Ÿæˆ
        if verbose:
            print(f"   å¼€å§‹ç”Ÿæˆ... (D={self.D}, scale={self.scale}, N={self.N})")
        
        # ILVR æ¨¡å¼éœ€è¦æ¢¯åº¦ï¼Œä¸ä½¿ç”¨ no_grad
        generated_images = self.diffusion.p_sample_loop(
            self.model,
            images.shape,
            clip_denoised=True,
            model_kwargs=model_kwargs,
            noise=images,
            N=self.N,
            D=self.D,
            scale=self.scale
        )
        
        # è½¬æ¢å›æ—¶é—´åºåˆ—
        generated_signals = self._image_to_eeg(generated_images)
        
        # åå½’ä¸€åŒ–
        generated_signals = self._denormalize_data(generated_signals, data_min, data_max)
        
        if verbose:
            print(f"   âœ… ç”Ÿæˆå®Œæˆ")
            print(f"   è¾“å‡ºå½¢çŠ¶: {generated_signals.shape}")
        
        if return_images:
            return original_data, generated_signals, images.cpu().detach().numpy(), generated_images.cpu().detach().numpy()
        else:
            return original_data, generated_signals
    
    def generate_batches(
        self,
        eeg_data: np.ndarray,
        batch_size: int = 16,
        verbose: bool = True
    ):
        """
        æ‰¹é‡ç”Ÿæˆ EEG ä¿¡å·ï¼ˆç”Ÿæˆå™¨æ¨¡å¼ï¼‰
        
        Args:
            eeg_data: è¾“å…¥ EEG æ•°æ® (trials, channels, timepoints)
            batch_size: æ‰¹æ¬¡å¤§å°
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
        Yields:
            (original_batch, generated_batch) å…ƒç»„
        """
        num_trials = len(eeg_data)
        num_batches = (num_trials + batch_size - 1) // batch_size
        
        if verbose:
            print(f"\nğŸ”„ æ‰¹é‡ç”Ÿæˆ EEG ä¿¡å·...")
            print(f"   æ€»æ ·æœ¬æ•°: {num_trials}")
            print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
            print(f"   æ€»æ‰¹æ¬¡æ•°: {num_batches}")
        
        for i in range(num_batches):
            start_idx = i * batch_size
            end_idx = min(start_idx + batch_size, num_trials)
            
            if verbose:
                print(f"\n   æ‰¹æ¬¡ {i+1}/{num_batches} [{start_idx}:{end_idx}]")
            
            batch_data = eeg_data[start_idx:end_idx]
            original, generated = self.generate(batch_data, verbose=False)
            
            yield original, generated


# ä¾¿æ·å‡½æ•°
def generate_eeg_signals(
    eeg_data: np.ndarray,
    model_path: str,
    device: Optional[str] = None,
    D: int = 8,
    scale: float = 1.0,
    **kwargs
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ä¾¿æ·å‡½æ•°ï¼šä¸€è¡Œä»£ç ç”Ÿæˆ EEG ä¿¡å·
    
    Args:
        eeg_data: è¾“å…¥ EEG æ•°æ® (trials, channels, timepoints)
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        device: è®¾å¤‡ ("cuda", "cpu", None=è‡ªåŠ¨)
        D: é¢‘ç‡å¼•å¯¼ä¸‹é‡‡æ ·å€æ•°
        scale: é¢‘ç‡å¼•å¯¼å¼ºåº¦
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        original_signals: åŸå§‹ä¿¡å·
        generated_signals: ç”Ÿæˆä¿¡å·
    
    ç¤ºä¾‹:
        >>> original, generated = generate_eeg_signals(
        ...     eeg_data=test_data,
        ...     model_path="models/model.pt",
        ...     D=4,
        ...     scale=6.0
        ... )
    """
    generator = EEGGenerator(
        model_path=model_path,
        device=device,
        D=D,
        scale=scale,
        **kwargs
    )
    return generator.generate(eeg_data)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("EEG Generator æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    test_data = np.random.randn(10, 22, 1000) * 50
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
    
    # æ–¹å¼ 1: ä½¿ç”¨ç±»
    print("\næ–¹å¼ 1: ä½¿ç”¨ EEGGenerator ç±»")
    generator = EEGGenerator(
        model_path="models/test_model.pt",  # æ›¿æ¢ä¸ºå®é™…æ¨¡å‹è·¯å¾„
        D=8,
        scale=1.0
    )
    original, generated = generator.generate(test_data)
    print(f"åŸå§‹ä¿¡å·å½¢çŠ¶: {original.shape}")
    print(f"ç”Ÿæˆä¿¡å·å½¢çŠ¶: {generated.shape}")
    
    # æ–¹å¼ 2: ä½¿ç”¨ä¾¿æ·å‡½æ•°
    print("\næ–¹å¼ 2: ä½¿ç”¨ä¾¿æ·å‡½æ•°")
    original, generated = generate_eeg_signals(
        eeg_data=test_data,
        model_path="models/test_model.pt",
        D=8,
        scale=1.0
    )
    
    # æ–¹å¼ 3: æ‰¹é‡ç”Ÿæˆ
    print("\næ–¹å¼ 3: æ‰¹é‡ç”Ÿæˆ")
    for i, (orig_batch, gen_batch) in enumerate(generator.generate_batches(test_data, batch_size=4)):
        print(f"  æ‰¹æ¬¡ {i+1}: åŸå§‹={orig_batch.shape}, ç”Ÿæˆ={gen_batch.shape}")

