"""
ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼ŒåŸºäºå‚è€ƒ EEG æ•°æ®ç”Ÿæˆæ–°çš„ EEG æ•°æ®
"""

import argparse
import os
import sys
import numpy as np
import torch as th
from tqdm import tqdm
import math

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from eeg_adapt.guided_diffusion import dist_util, logger
from eeg_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)

# å½’ä¸€åŒ–å‡½æ•°
def normalize_eeg_data(data):
    """å°†æ•°æ®å½’ä¸€åŒ–åˆ° [-1, 1]"""
    data_min = data.min()
    data_max = data.max()
    return 2 * (data - data_min) / (data_max - data_min) - 1, data_min, data_max

def denormalize_eeg_data(data, data_min, data_max):
    """å°†æ•°æ®ä» [-1, 1] è¿˜åŸåˆ°åŸå§‹èŒƒå›´"""
    return (data + 1) / 2 * (data_max - data_min) + data_min


class DelayEmbedder:
    """Delay embedding transformation"""
    
    def __init__(self, device, seq_len, delay, embedding):
        self.device = device
        self.seq_len = seq_len
        self.delay = delay
        self.embedding = embedding
        self.img_shape = None
    
    def pad_to_square(self, x, mask=0):
        """Pads the input tensor x to make it square along the last two dimensions."""
        _, _, cols, rows = x.shape
        max_side = max(cols, rows)
        padding = (0, max_side - rows, 0, max_side - cols)
        x_padded = th.nn.functional.pad(x, padding, mode='constant', value=mask)
        return x_padded
    
    def ts_to_img(self, signal, pad=True, mask=0):
        """
        å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºå›¾åƒ
        Args:
            signal: (batch, length, features) - EEGæ•°æ®
            pad: æ˜¯å¦å¡«å……åˆ°æ­£æ–¹å½¢
        Returns:
            x_image: (batch, features, H, W)
        """
        batch, length, features = signal.shape
        if self.seq_len != length:
            self.seq_len = length
        
        x_image = th.zeros((batch, features, self.embedding, self.embedding))
        i = 0
        while (i * self.delay + self.embedding) <= self.seq_len:
            start = i * self.delay
            end = start + self.embedding
            x_image[:, :, :, i] = signal[:, start:end].permute(0, 2, 1)
            i += 1
        
        # å¤„ç†å‰©ä½™éƒ¨åˆ†
        if i * self.delay != self.seq_len and i * self.delay + self.embedding > self.seq_len:
            start = i * self.delay
            end = signal[:, start:].permute(0, 2, 1).shape[-1]
            x_image[:, :, :end, i] = signal[:, start:].permute(0, 2, 1)
            i += 1
        
        self.img_shape = (batch, features, self.embedding, i)
        x_image = x_image.to(self.device)[:, :, :, :i]
        
        if pad:
            x_image = self.pad_to_square(x_image, mask)
        
        return x_image


def img_to_ts(image_data):
    """
    å°†å›¾åƒæ•°æ®è½¬æ¢ä¸ºæ—¶é—´åºåˆ—æ ¼å¼ï¼ˆä½¿ç”¨æ—¶é—´å»¶è¿ŸåµŒå…¥çš„é€†è¿‡ç¨‹ï¼‰
    
    å‚æ•°:
        image_data: torch tensor, shape=(batch, 22, 64, 64)
    
    è¿”å›:
        time_series: torch tensor, shape=(batch, 1000, 22)
    """
    batch, channels, rows, cols = image_data.shape
    
    # å‚æ•°è®¾ç½®
    seq_len = 1000
    delay = 15
    embedding = 64
    
    # åˆå§‹åŒ–é‡å»ºçš„æ—¶é—´åºåˆ—
    reconstructed_x_time_series = th.zeros((batch, channels, seq_len))
    
    # é‡å»ºæ—¶é—´åºåˆ—ï¼ˆæ—¶é—´å»¶è¿ŸåµŒå…¥çš„é€†è¿‡ç¨‹ï¼‰
    for i in range(cols - 1):
        start = i * delay
        end = start + embedding
        reconstructed_x_time_series[:, :, start:end] = image_data[:, :, :, i]
    
    # å¤„ç†æœ€åä¸€åˆ—ï¼ˆç‰¹æ®Šæƒ…å†µï¼‰
    start = (cols - 1) * delay
    end = reconstructed_x_time_series[:, :, start:].shape[-1]
    reconstructed_x_time_series[:, :, start:] = image_data[:, :, :end, cols - 1]
    
    # è½¬æ¢ç»´åº¦: (batch, channels, seq_len) -> (batch, seq_len, channels)
    reconstructed_x_time_series = reconstructed_x_time_series.permute(0, 2, 1)
    
    return reconstructed_x_time_series


def load_eeg_data(data_path):
    """
    åŠ è½½ EEG æ•°æ®
    
    å‚æ•°:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
    
    è¿”å›:
        data: numpy æ•°ç»„, shape=(trials, 22, 1000)
    """
    print(f"ä» {data_path} åŠ è½½ EEG æ•°æ®...")
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    data = np.load(data_path)
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}")
    
    # ç¡®ä¿æ•°æ®æ ¼å¼ä¸º (trials, channels, timepoints)
    if data.ndim == 4 and data.shape[1] == 1:
        # å¦‚æœæ˜¯ (trials, 1, channels, timepoints)ï¼Œå»æ‰ç¬¬äºŒç»´
        data = data.squeeze(1)
        print(f"å»æ‰ç»´åº¦1åçš„å½¢çŠ¶: {data.shape}")
    
    if data.shape[1] == 1000 and data.shape[2] == 22:
        # å¦‚æœæ˜¯ (trials, timepoints, channels)ï¼Œè½¬æ¢ä¸º (trials, channels, timepoints)
        data = np.transpose(data, (0, 2, 1))
        print(f"è½¬æ¢æ•°æ®æ ¼å¼ä¸º: {data.shape}")
    
    return data


def create_eeg_reference_loader(data_path, batch_size, embedding_size=64, delay=15):
    """
    åˆ›å»º EEG å‚è€ƒæ•°æ®åŠ è½½å™¨
    
    å‚æ•°:
        data_path: EEG æ•°æ®è·¯å¾„ (trials, 22, 1000)
        batch_size: æ‰¹æ¬¡å¤§å°
        embedding_size: embedding ç»´åº¦
        delay: delay å‚æ•°
    
    è¿”å›:
        ç”Ÿæˆå™¨ï¼Œæ¯æ¬¡yieldä¸€ä¸ªbatchçš„å›¾åƒæ•°æ®
    """
    # åŠ è½½æ•°æ®
    eeg_data = load_eeg_data(data_path)
    num_trials = len(eeg_data)
    
    print(f"\nğŸ“Š æ•°æ®ä¿¡æ¯:")
    print(f"   æ€» trials:    {num_trials}")
    print(f"   æ•°æ®å½¢çŠ¶:     {eeg_data.shape}")
    print(f"   é€šé“æ•°:       {eeg_data.shape[1]}")
    print(f"   æ—¶é—´ç‚¹æ•°:     {eeg_data.shape[2]}")
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    data_min_orig = eeg_data.min()
    data_max_orig = eeg_data.max()
    print(f"\n   åŸå§‹æ•°æ®èŒƒå›´: [{data_min_orig:.6f}, {data_max_orig:.6f}]")
    print(f"   å‡å€¼:         {eeg_data.mean():.6f}")
    print(f"   æ ‡å‡†å·®:       {eeg_data.std():.6f}")
    
    # åˆ›å»º embedder
    device = th.device("cuda" if th.cuda.is_available() else "cpu")
    seq_len = eeg_data.shape[2]  # 1000
    embedder = DelayEmbedder(device, seq_len, delay, embedding_size)
    
    # æ™ºèƒ½å½’ä¸€åŒ–åˆ° [-1, 1]
    if -1.1 <= data_min_orig and data_max_orig <= 1.1:
        print(f"   âœ… æ•°æ®å·²åœ¨ [-1, 1] èŒƒå›´ï¼Œè·³è¿‡å½’ä¸€åŒ–")
        eeg_data_normalized = eeg_data
        data_min = data_min_orig
        data_max = data_max_orig
    else:
        print(f"   ğŸ”„ å½’ä¸€åŒ–æ•°æ®åˆ° [-1, 1] èŒƒå›´...")
        eeg_data_normalized, data_min, data_max = normalize_eeg_data(eeg_data)
        print(f"   âœ… å½’ä¸€åŒ–å®Œæˆ: [{eeg_data_normalized.min():.6f}, {eeg_data_normalized.max():.6f}]")
    
    # æ‰¹é‡å¤„ç†å¹¶ç”Ÿæˆ
    num_batches = (num_trials + batch_size - 1) // batch_size
    
    for i in range(num_batches):
        start_idx = i * batch_size
        end_idx = min(start_idx + batch_size, num_trials)
        actual_batch_size = end_idx - start_idx
        
        # è·å–å½“å‰æ‰¹æ¬¡
        batch_data = eeg_data_normalized[start_idx:end_idx]  # (batch, 22, 1000)
        
        # è½¬æ¢ä¸º (batch, 1000, 22) ä»¥é€‚é… ts_to_img
        batch_data = np.transpose(batch_data, (0, 2, 1))
        batch_tensor = th.from_numpy(batch_data).float().to(device)
        
        # è½¬æ¢ä¸ºå›¾åƒæ ¼å¼
        batch_images = embedder.ts_to_img(batch_tensor, pad=True, mask=0)
        
        yield batch_images, actual_batch_size, data_min, data_max
    
    return data_min, data_max


def main():
    args = create_argparser().parse_args()

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("åˆ›å»ºæ¨¡å‹...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(args.model_path, map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()
    model.eval()

    logger.log("creating resizers...")
    assert math.log(args.D, 2).is_integer(), f"D å¿…é¡»æ˜¯ 2 çš„å¹‚æ¬¡ï¼Œå½“å‰å€¼: {args.D}"
    
    logger.log(f"é¢‘ç‡å¼•å¯¼å‚æ•°: D={args.D}, scale={args.scale}")
    if args.N is not None:
        logger.log(f"å°†ä»æ—¶é—´æ­¥ N={args.N} å¼€å§‹é‡‡æ ·")

    logger.log("åŠ è½½ EEG æ•°æ®å¹¶è½¬æ¢ä¸ºå›¾åƒæ ¼å¼...")
    data_loader = create_eeg_reference_loader(
        args.eeg_data_path,
        args.batch_size,
        embedding_size=args.embedding_size,
        delay=args.delay,
    )

    logger.log("å¼€å§‹ç”Ÿæˆæ ·æœ¬...")
    all_generated_signals = []
    all_generated_images = []
    count = 0
    
    # è®°å½•å½’ä¸€åŒ–å‚æ•°ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªbatchçš„å‚æ•°ï¼‰
    data_min, data_max = None, None

    for batch_images, actual_batch_size, batch_data_min, batch_data_max in data_loader:
        # è®°å½•å½’ä¸€åŒ–å‚æ•°
        if data_min is None:
            data_min = batch_data_min
            data_max = batch_data_max
        
        # å°†æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
        batch_images = batch_images.to(dist_util.dev())
        
        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        model_kwargs = {}
        if args.class_cond:
            # å¦‚æœéœ€è¦ç±»åˆ«æ¡ä»¶ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
            pass
        
        # æ‰§è¡Œé‡‡æ · (ä½¿ç”¨åŸºäºæ¢¯åº¦çš„é¢‘ç‡å¼•å¯¼)
        logger.log(f"å¤„ç† batch {count+1}, åŒ…å« {actual_batch_size} ä¸ªæ ·æœ¬...")
        
        # å‡†å¤‡å‚è€ƒå›¾åƒ
        model_kwargs["ref_img"] = batch_images
        
        sample = diffusion.p_sample_loop(
            model,
            (actual_batch_size, args.in_channels, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs=model_kwargs,
            noise=batch_images,
            N=args.N,
            D=args.D,
            scale=args.scale
        )
        
        # ä¿å­˜ç”Ÿæˆçš„å›¾åƒï¼ˆå¯é€‰ï¼‰
        if args.save_images:
            all_generated_images.append(sample.cpu())
        
        # è½¬æ¢å›æ—¶é—´åºåˆ—
        logger.log(f"å°†ç”Ÿæˆçš„å›¾åƒè½¬æ¢å›æ—¶é—´åºåˆ—...")
        generated_signals = img_to_ts(sample)  # (batch, 1000, 22)
        
        # è½¬æ¢ä¸º (batch, 22, 1000) æ ¼å¼
        generated_signals = generated_signals.permute(0, 2, 1)
        
        # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        all_generated_signals.append(generated_signals.cpu().numpy())
        
        count += 1
        logger.log(f"å·²ç”Ÿæˆ {count * args.batch_size} ä¸ªæ ·æœ¬")

    # åˆå¹¶æ‰€æœ‰ç”Ÿæˆçš„ä¿¡å·
    all_generated_signals = np.concatenate(all_generated_signals, axis=0)
    
    # åå½’ä¸€åŒ–
    logger.log("åå½’ä¸€åŒ–æ•°æ®...")
    all_generated_signals = denormalize_eeg_data(all_generated_signals, data_min, data_max)
    
    # ä¿å­˜ç”Ÿæˆçš„ä¿¡å·
    output_path = os.path.join(args.save_dir, "test_data_gen.npy")
    np.save(output_path, all_generated_signals)
    logger.log(f"ç”Ÿæˆçš„ä¿¡å·å·²ä¿å­˜åˆ°: {output_path}")
    logger.log(f"è¾“å‡ºå½¢çŠ¶: {all_generated_signals.shape}")
    
    # å¯é€‰ï¼šä¿å­˜ç”Ÿæˆçš„å›¾åƒ
    if args.save_images:
        all_generated_images = th.cat(all_generated_images, dim=0)
        image_output_path = os.path.join(args.save_dir, "generated_eeg_images.npy")
        np.save(image_output_path, all_generated_images.numpy())
        logger.log(f"ç”Ÿæˆçš„å›¾åƒå·²ä¿å­˜åˆ°: {image_output_path}")
    
    logger.log("é‡‡æ ·å®Œæˆï¼")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        batch_size=16,
        use_ddim=False,
        model_path="",
        eeg_data_path="",  # EEG æ•°æ®è·¯å¾„ (trials, 22, 1000)
        save_dir="./eeg_samples",
        embedding_size=64,  # åµŒå…¥ç»´åº¦
        delay=15,  # delay å‚æ•°
        save_images=False,  # æ˜¯å¦ä¿å­˜å›¾åƒæ ¼å¼
        # é¢‘ç‡å¼•å¯¼å‚æ•°ï¼ˆåŸºäºæ¢¯åº¦çš„æ–¹æ³•ï¼‰
        D=8,  # é¢‘ç‡å¼•å¯¼çš„ä¸‹é‡‡æ ·å€æ•° (æ§åˆ¶é¢‘ç‡çº§åˆ«)
        scale=1.0,  # é¢‘ç‡å¼•å¯¼çš„å¼ºåº¦ (æ¢¯åº¦ç¼©æ”¾ç³»æ•°)
        N=None,  # å¯é€‰ï¼šä»ç‰¹å®šæ—¶é—´æ­¥å¼€å§‹é‡‡æ ·
    )
    defaults.update(model_and_diffusion_defaults())
    # ä¸º EEG æ•°æ®è®¾ç½®é»˜è®¤å‚æ•°
    defaults["in_channels"] = 22
    defaults["image_size"] = 64
    
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å’ŒåŸºäºæ¢¯åº¦çš„é¢‘ç‡å¼•å¯¼æ–¹æ³•ç”Ÿæˆ EEG æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
  # åŸºæœ¬ä½¿ç”¨ (æ ‡å‡†é¢‘ç‡å¼•å¯¼)
  python eeg_sample.py --model_path models/ema_0.9999_200000.pt \\
                       --eeg_data_path datasets/eegdata/bci2a/resub1234567/test_data.npy \\
                       --save_dir ./output
        """
    )
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()
